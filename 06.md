### 从html中提取文本
- 用xpath——/html/head/title/text()

### xpath学习重点
- 使用xpath helper或者是chrome中的copy xpath都是从element中提取的数据，但是爬虫获取的是url对应的响应，往往和element不一样
- 标签到标签之间的过渡用'/'
- 获取文本
 - 'a/text()' 获取a下的文本
 - 'a//text()' 获取a下所有标签的文本
 - //a[text()='下一页>']  选择文本为下一页三个字的a标签
- '/.'表示当前 '/..'表示上一级
- '@符号'
 - 'a/@href' 获取属性
 - '//ul[@id = "detail-list"]' 对元素进行定位 一般选取有class或者id的
- '//'
 - 在xpath开始的时候表示从当前html中任意位置开始选择
 - 'li//a'表示的是li下任何一个标签

### 用豆瓣排行榜实测
- //div[@class = "indent"]//div[@class = "pl2"]/a//text()
- 用双斜杠才能获取a标签里面所有的文本

### 取百度搜索下的所有地址
-//div[@id = "content_left"]//div/h3/a/@href

### lxml使用注意点
- lxml能够修正HTML代码，但是可能会改错了
 - 使用etree.tostring观察修改之后的html的样子，根据修改之后的html字符串写xpath
- lxml能够接收bytes和str字符串
- 提取页面数据的思路
 - 先分组，取到一个包含分组标签的列表
 - 遍历，取其中每一组进行数据的提取，不会造成数据的对应错乱
